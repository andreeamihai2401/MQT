1. Create topic a topic having 3 brokers as --bootstrap-server. 
The brokers' ports are taken from the docker-compose_kafka.yml
The topic should have 3 partitions and replication-factor 3
The name of the topic is events1. 

/usr/bin/kafka-topics --create --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --partitions 3 --replication-factor 3 --topic events1
    
Create a second topic having 3 brokers as --bootstrap-server. 
The brokers' ports are taken from the docker-compose_kafka.yml
The topic should have 4 partitions and replication-factor 2
The name of the topic is events2. 	

/usr/bin/kafka-topics --create --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --partitions 4 --replication-factor 2 --topic events2	

2. List all topics 

/usr/bin/kafka-topics --list --bootstrap-server kafka:9092,kafka:9093,kafka:9094

3. Send data. Create a Producer and send data to events2 topic, using key and ',' as separator.

/usr/bin/kafka-console-producer --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --topic events2 --property key.parse=true --property key.separator=","

3. Read the data. Create a Consumer and read data from events2 topic.  
No data will be shown because we do not have --from-beginning property

/usr/bin/kafka-console-consumer --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --topic events2 --property key.parse=true --property key.separator=","

4. Run consumer and print the partition
Check that messages with the same key go to the same partition. Notice, that messages may come in a different order, when they are in different partitions.

/usr/bin/kafka-console-consumer --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --topic events2 --property key.parse=true --property key.separator="," --property print.partition=true --from-beginning

5. Run with specifying consumer group and printing the partition and the offset
Check that messages with the same key go to the same partition. Notice, that messages may come in a different order, when they are in different partitions.

/usr/bin/kafka-console-consumer --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --topic events2 --group group1 --property key.parse=true --property key.separator="," --property print.partition=true --property print.offset=true --from-beginning 

6. Create a group of 2 consumers. 
Now we have two consumers within one group.

/usr/bin/kafka-console-consumer --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --topic events2 --group group1 --property key.parse=true --property key.separator="," --property print.partition=true --property print.offset=true --from-beginning 

7. Send more data with our producer
Check how the messages are distributed between the 2 consumers. 

The first 2 partitions are distributed to first consumer, then partition 2 and 3 are distributed to the second consumer.  

8. Delete topic

/usr/bin/kafka-topics --delete --bootstrap-server kafka:9092,kafka2:9093,kafka3:9094 --topic events2